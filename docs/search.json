[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "datacleanr.html",
    "href": "datacleanr.html",
    "title": "10. Shiny apps for data qa and data viz",
    "section": "",
    "text": "Load packages\n\nlibrary (datacleanr) # for interactive data viz\n\n\ndf <-read.csv ('example_data/sunflower_data_broken.csv')\n\nThe dcr_app() command launches the interactive app.\n\ndcr_app(df)"
  },
  {
    "objectID": "data_in_range.html",
    "href": "data_in_range.html",
    "title": "4. Data in range",
    "section": "",
    "text": "library(tidyverse) # general data wrangling\nlibrary(summarytools)\n\nIf you have already completed the Scrambled data types module you will have created this file. For those who prefer to jump in at the middle, the original dataset with mis-entered dates and missing value codes FIXED can be downloaded here and tucked into your example_data directory.\n\ndf <- read.csv(\"example_data/sunflower_data_1.csv\")\n\nWe can use the tidyverse package to make ourselves a quick table of ranges to scan.\n\n# This code reads a dataframe 'df' and selects only the numeric columns. It then pivots the\n# data into a longer format, groups by the column names, and summarizes the minimum and\n# maximum values for each column. The resulting output is a dataframe with two columns:\n# 'name' and 'value', where 'name' is the column name and 'value' is a list containing\n# the minimum and maximum values for that column.\nmin_max <- df %>%\n  select(where(is.numeric)) %>%\n  pivot_longer(cols = everything()) %>%\n  group_by(name) %>%\n  summarize_at(\"value\", list(min = ~ min(.x, na.rm = TRUE), max = ~ max(.x, na.rm = TRUE)))\n\n\n\n\n\n\nname\nmin\nmax\n\n\n\n\nharvest_moisture_pct\n5.82\n43.4\n\n\nheight_in\n31.00\n188.0\n\n\nyear\n1978.00\n2022.0\n\n\nyield_lb_acre\n230.00\n3426.0\n\n\n\n\n\nIf you completed the Missing data module you will recall that the summarytools package also gives us this information (and more!) in the Stats/Values column.\n\nview(dfSummary(df))\n\n\n\n\n\nData Frame Summary\ndf\nDimensions: 2685 x 8\n  Duplicates: 0\n\n\n  \n    \n      Variable\n      Stats / Values\n      Freqs (% of Valid)\n      Graph\n      Missing\n    \n  \n  \n    \n      harvest_date\n[character]\n      1. 1999-10-132. 2006-10-233. 2005-10-254. 1997-09-305. 1993-10-216. 1994-10-127. 2000-10-178. 2004-10-279. 2010-10-2110. 2009-11-16[ 14 others ]\n      113(6.9%)107(6.6%)105(6.4%)99(6.1%)98(6.0%)98(6.0%)90(5.5%)80(4.9%)76(4.7%)73(4.5%)692(42.4%)\n      \n      1054\n(39.3%)\n    \n    \n      harvest_moisture_pct\n[numeric]\n      Mean (sd) : 14.3 (6.1)min ≤ med ≤ max:5.8 ≤ 11.8 ≤ 43.4IQR (CV) : 7.9 (0.4)\n      413 distinct values\n      \n      656\n(24.4%)\n    \n    \n      height_in\n[numeric]\n      Mean (sd) : 62.2 (19.6)min ≤ med ≤ max:31 ≤ 60 ≤ 188IQR (CV) : 10 (0.3)\n      376 distinct values\n      \n      398\n(14.8%)\n    \n    \n      yield_lb_acre\n[numeric]\n      Mean (sd) : 1954.6 (497.5)min ≤ med ≤ max:230 ≤ 2001 ≤ 3426IQR (CV) : 641.1 (0.3)\n      1635 distinct values\n      \n      73\n(2.7%)\n    \n    \n      year\n[integer]\n      Mean (sd) : 1999.5 (11.4)min ≤ med ≤ max:1978 ≤ 1999 ≤ 2022IQR (CV) : 17 (0)\n      40 distinct values\n      \n      0\n(0.0%)\n    \n    \n      hybrid\n[character]\n      1. 8942. Falcon3. SF1874. 1415. Badger DMR6. 8D3107. Hornet8. SF2709. 3845 HO10. 432 E[ 1757 others ]\n      27(1.0%)12(0.4%)10(0.4%)9(0.3%)9(0.3%)8(0.3%)8(0.3%)8(0.3%)7(0.3%)7(0.3%)2580(96.1%)\n      \n      0\n(0.0%)\n    \n    \n      emergence_date\n[character]\n      1. 1999-06-042. 2006-06-043. 1993-05-294. 2005-05-255. 1997-05-316. 1999-06-037. 2006-06-038. 1994-05-279. 2000-06-0410. 1993-05-28[ 144 others ]\n      34(2.5%)33(2.4%)28(2.1%)27(2.0%)25(1.8%)23(1.7%)23(1.7%)22(1.6%)22(1.6%)21(1.6%)1094(80.9%)\n      \n      1333\n(49.6%)\n    \n    \n      planting_date\n[character]\n      1. 2006-06-012. 2005-05-233. 1997-05-294. 1993-05-265. 1994-05-256. 2000-06-027. 2004-05-268. 2010-05-209. 2009-05-2710. 1991-05-28[ 56 others ]\n      107(6.9%)105(6.7%)99(6.3%)98(6.3%)98(6.3%)90(5.8%)80(5.1%)76(4.9%)73(4.7%)72(4.6%)663(42.5%)\n      \n      1124\n(41.9%)\n    \n  \n\nGenerated by summarytools 1.0.1 (R version 4.2.2)2024-02-23\n\n\n\nOften a visual assessment is key to figuring out what is wrong. Most biological data are normally or lognormally distributed. What is that suspect lump of data in height_in?\n\ntoo_tall <- df %>%\n  # filter on values >3d greater than the mean\n  #filter(height_in > 62.2 + 19.6 * 3)\n  filter(height_in > (mean(height_in, na.rm = TRUE)+3*sd(height_in, na.rm = TRUE)))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nharvest_date\nharvest_moisture_pct\nheight_in\nyield_lb_acre\nyear\nhybrid\nemergence_date\nplanting_date\n\n\n\n\n2004-10-27\n23.6\n173\n1310\n2004\n894\n2004-05-29\n2004-05-26\n\n\n2004-10-27\n26.9\n160\n1421\n2004\n9405\n2004-05-30\n2004-05-26\n\n\n2004-10-27\n24.4\n170\n1597\n2004\n9441\n2004-05-29\n2004-05-26\n\n\n2004-10-27\n25.2\n157\n1609\n2004\nCL 55-15\n2004-05-28\n2004-05-26\n\n\n2004-10-27\n22.2\n155\n1687\n2004\nExp 15\n2004-05-28\n2004-05-26\n\n\n2004-10-27\n24.1\n168\n1603\n2004\nExp T-1\n2004-05-29\n2004-05-26\n\n\n2004-10-27\n23.4\n165\n1529\n2004\nExp T-2\n2004-05-30\n2004-05-26\n\n\n2004-10-27\n23.7\n175\n1474\n2004\nExp T-3\n2004-05-31\n2004-05-26\n\n\n2004-10-27\n21.3\n165\n1594\n2004\nMSR 50\n2004-05-29\n2004-05-26\n\n\n2004-10-27\n21.2\n188\n2027\n2004\nMSR 51\n2004-05-28\n2004-05-26\n\n\n\n\n\nAll appear to be from a single year, which is either (a) the tallest year in sunflower history or (b) a coding error. Perhaps the data were recorded in centimeters instead of inches?\n\nnot_too_tall <- df %>%\n  anti_join(., too_tall)\n\nJoining with `by = join_by(harvest_date, harvest_moisture_pct, height_in,\nyield_lb_acre, year, hybrid, emergence_date, planting_date)`\n\nmean(not_too_tall$height_in, na.rm = TRUE)\n\n[1] 58.8046\n\nmean(too_tall$height_in, na.rm = TRUE)\n\n[1] 156.1266\n\n# does converting to cm to inches fix the problem?\nmean(too_tall$height_in, na.rm = TRUE) / 2.54\n\n[1] 61.46716\n\n\nIt is always best to double check your field notes, your assistants field notes etc to verify your assumptions when correcting data after the fact! But sometimes, the unit errors are pretty easy to detect and erroneous data can be easily corrected after the fact.\n\ntoo_tall <- too_tall %>%\n  mutate(height_in = height_in / 2.54)\n\ndf <- bind_rows(too_tall, not_too_tall)\n\nCarry on and be merry!"
  },
  {
    "objectID": "data_types.html",
    "href": "data_types.html",
    "title": "1. Scrambled data types",
    "section": "",
    "text": "library(naniar) # to homogenize missing value codes\nlibrary(tidyverse) # general data wrangling\n\n\ndf <- read.csv(\"example_data/sunflower_data_broken.csv\")\n\nTo understand a little bit about the data, it can be helpful to get a brief summary of the contents\n\ndplyr::glimpse(df)\n\nRows: 2,685\nColumns: 9\n$ X                    <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15…\n$ harvest_date         <int> 19970930, 19970930, 19970930, 19970930, 19970930,…\n$ harvest_moisture_pct <dbl> 8.4, 9.9, 11.0, 10.0, 10.3, 9.7, 9.7, 8.1, 9.5, 9…\n$ height_in            <chr> \"57\", \"62\", \"56\", \"60\", \"58\", \"58\", \"66\", \"60\", \"…\n$ planting_date        <chr> \"19970529\", \"19970529\", \"19970529\", \"19970529\", \"…\n$ yield_lb_acre        <dbl> 2542, 2179, 2510, 2225, 2208, 2326, 2319, 2224, 2…\n$ Year                 <int> 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1…\n$ Hybrid               <chr> \"AP2098\", \"AP3470\", \"AK7304\", \"AK7305\", \"AK7306\",…\n$ emergence_date       <int> 19970533, 19970531, 19970531, 19970532, 19970532,…\n\n\nA glimpse at our dataset tells us something about its structure. Ideally, you are the data collector and already know all of this. The first column (X) appears to be an index variable. Sometimes this is intentional; more often it occurs when people write out files in R and forget to include the row.names = F argument.\nSome things should strike you as potentially problematic about this dataset:\n\nThere are two date fields, but one is encoded as a character and one as an integer.\nHeight (with units inches) is encoded as a character.\n\nIt is very easy to convert everything that should be numeric into a numeric field, but doing this blindly risks wiping out actual data. For example - what if all the low values were entered as ‘below detection level’. Setting all those values to ‘NA’ would bias the results. It’s important to suss out what those mystery values are, and why they are there in the first place.\nThere surely is an existing R package that does this more elegantly, but I have yet to discover it. So I wrote a short function that iterates across columns and pulls out all rows of data that cannot successfully be converted to a numeric value. This function (check_non_numeric) is designed to check if a specified column in a dataframe contains non-numeric values. The function takes two arguments: df, which is the dataframe to be checked, and var, which is the name of the column in the dataframe to be checked.\nCopy the function below to use in the next set of code.\n\n# Function to find non-numeric values in a column and inspect\n\n# @param df data frame\n# @param var variable to check\n# @return data frame with non-numeric values\ncheck_non_numeric <- function(df, var) {\n  row_probs <- which(!is.na(df[[var]]) & is.na(suppressWarnings(as.numeric(df[[var]]))))\n  if (length(row_probs > 0)) {\n    warning(paste(\"Check file for\", var, \"\\n\"))\n    return(df[row_probs, ])\n  } else {\n    cat(paste(\"all values are numeric for \", var, \"\\n\"))\n    return(NULL)\n  }\n}\n\nTo inspect our data for possible problems in numeric columns, we need to first define all columns that we think should be numeric. Since the majority of the data appear to be numeric, it’s often easier to just define which variables are NOT numeric, and test the remaining set.\n\n# define numeric columns as all of those that aren't non-numeric\nnon_numeric_cols <- \"Hybrid\"\nnumeric_cols <- setdiff(names(df), non_numeric_cols)\n\nWe can now iterate over all the columns we think should contain numeric data and look for problems.\n\n# set up a list to put numeric check results into\nall_checks <- list()\n\nfor (i in numeric_cols) {\n  all_checks[[i]] <- check_non_numeric(df, i)\n}\n\nall values are numeric for  X \nall values are numeric for  harvest_date \nall values are numeric for  harvest_moisture_pct \n\n\nWarning in check_non_numeric(df, i): Check file for height_in \n\n\nWarning in check_non_numeric(df, i): Check file for planting_date \n\n\nall values are numeric for  yield_lb_acre \nall values are numeric for  Year \nall values are numeric for  emergence_date \n\n# resulting list will just have the things you still need to check\nnames(all_checks)\n\n[1] \"height_in\"     \"planting_date\"\n\n\nThe function has told use we have some non-numeric values in the variables “height_in” and “planting date”. Let’s look at what these problems are to determine what to do about them.\n\nView(all_checks[[\"height_in\"]])\n\n\n\n\n\n \n  \n      \n    X \n    harvest_date \n    harvest_moisture_pct \n    height_in \n    planting_date \n    yield_lb_acre \n    Year \n    Hybrid \n    emergence_date \n  \n \n\n  \n    40 \n    40 \n    19970930 \n    9.5 \n    na \n    19970529 \n    2381 \n    1997 \n    ST2117 \n    19970532 \n  \n  \n    475 \n    475 \n    20021031 \n    13.3 \n    N/A \n    20020529 \n    2008 \n    2002 \n    F00001 \n    20020533 \n  \n\n\n\n\n\nWe can see from the above there are two different missing value codes included in the height column. Having confidence in the issues, we can now set those to a proper missing value code. Here I’m going to run on the assumption that these two missing value codes may be found elsewhere, and replace them everywhere using the replace_with_na_all function. Note we could have also addressed this by defining multiple missing value codes when we initially read in the data.\n\n# replace non-standard missing value codes\ndf <- df %>% replace_with_na_all(\n  condition =\n    ~ .x %in% c(\"N/A\", \"na\")\n)\n\nNext, let’s inspect the planting date problems.\n\nView(all_checks[[\"planting_date\"]])\n\n\n\n\n\n \n  \n      \n    X \n    harvest_date \n    harvest_moisture_pct \n    height_in \n    planting_date \n    yield_lb_acre \n    Year \n    Hybrid \n    emergence_date \n  \n \n\n  \n    867 \n    867 \n    20101021 \n    11.7 \n    63 \n    5/20/2010 \n    1032 \n    2010 \n    F30008NS,CL \n    20100524 \n  \n  \n    868 \n    868 \n    20101021 \n    8.2 \n    64 \n    5/20/2010 \n    1244 \n    2010 \n    F51122NS,CL \n    20100522 \n  \n  \n    869 \n    869 \n    20101021 \n    8.6 \n    66 \n    5/20/2010 \n    1290 \n    2010 \n    F51137NS,CL \n    20100523 \n  \n  \n    870 \n    870 \n    20101021 \n    9.4 \n    71 \n    5/20/2010 \n    1354 \n    2010 \n    F51139NS,DM,CL \n    20100524 \n  \n  \n    871 \n    871 \n    20101021 \n    11.0 \n    67 \n    5/20/2010 \n    1236 \n    2010 \n    F51313NS,DM,CL \n    20100524 \n  \n  \n    872 \n    872 \n    20101021 \n    9.3 \n    64 \n    5/20/2010 \n    664 \n    2010 \n    F89036NS,DM,CL \n    20100522 \n  \n  \n    873 \n    873 \n    20101021 \n    10.0 \n    69 \n    5/20/2010 \n    230 \n    2010 \n    F89057NS,SU \n    20100522 \n  \n  \n    874 \n    874 \n    20101021 \n    8.4 \n    58 \n    5/20/2010 \n    1153 \n    2010 \n    F91033NS,SU \n    20100522 \n  \n  \n    875 \n    875 \n    20101021 \n    9.9 \n    65 \n    5/20/2010 \n    759 \n    2010 \n    306 DMR NS \n    20100527 \n  \n  \n    876 \n    876 \n    20101021 \n    8.5 \n    62 \n    5/20/2010 \n    1592 \n    2010 \n    3080 DMR NS \n    20100526 \n  \n\n\n\n\n\nIt appears that some of the data have dates entered as M/D/YYYY. To determine what to do about this, we need to see all the date formats that can be encountered.\n\nunique(sort(df[[\"planting_date\"]], decreasing = TRUE))\n\n\n\n\n\n \n  \n    planting_date \n  \n \n\n  \n    5/20/2010 \n  \n  \n    20220606 \n  \n  \n    20210526 \n  \n  \n    20200601 \n  \n  \n    20180605 \n  \n  \n    20170525 \n  \n  \n    20160527 \n  \n  \n    20150603 \n  \n  \n    20140603 \n  \n  \n    20130606 \n  \n\n\n\n\n\nIn this dataset, sometimes the date is encoded as an 8 digit integer YYYYMMDD while others have M/D/YYYY. Based on this information, we can use the lubridate package to interpret the dates entered in either format, and then consolidate into a single, proper date column. You will get some warnings! This is to be expected as we know that the date formatting differs among rows.\n\ndf <- df %>%\n  rename(planting_date_original = planting_date) %>%\n  mutate(\n    yyyymmdd = lubridate::ymd(planting_date_original),\n    mdy = lubridate::mdy(planting_date_original),\n    planting_date_corrected = coalesce(yyyymmdd, mdy)\n  )\n\nWarning: There were 2 warnings in `mutate()`.\nThe first warning was:\nℹ In argument: `yyyymmdd = lubridate::ymd(planting_date_original)`.\nCaused by warning:\n!  146 failed to parse.\nℹ Run `dplyr::last_dplyr_warnings()` to see the 1 remaining warning.\n\n\nAlways check your work!!\n\n# always check your work\nView(df %>%\n  filter(Year %in% c(2008:2012)) %>%\n  select(planting_date_original, planting_date_corrected) %>%\n  distinct())\n\n\n\n\n\n \n  \n    planting_date_original \n    planting_date_corrected \n  \n \n\n  \n    20090527 \n    2009-05-27 \n  \n  \n    5/20/2010 \n    2010-05-20 \n  \n  \n    20120606 \n    2012-06-06 \n  \n  \n    NA \n    NA \n  \n\n\n\n\n\nFinally, we can remove the temporary columns we created, and set all our remaining columns to the correct column types.\n\n# re define numeric columns - this time leaving off date\nnumeric_cols <- c(\"harvest_moisture_pct\", \"height_in\", \"yield_lb_acre\")\n\ndf <- df %>%\n  select(-yyyymmdd, -mdy, -planting_date_original, -X) %>%\n  rename(planting_date = planting_date_corrected) %>%\n  # while we are at it let's rename everything to lower case as\n  # variable capitalization is annoying and hard to remember\n  rename_all(tolower) %>%\n  # set harvest_date to a date rather than an integer\n  mutate(\n    harvest_date = lubridate::ymd(harvest_date),\n    emergence_date = lubridate::ymd(emergence_date)\n  ) %>%\n  mutate_at(numeric_cols, as.numeric)\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `emergence_date = lubridate::ymd(emergence_date)`.\nCaused by warning:\n!  279 failed to parse.\n\nglimpse(df)\n\nRows: 2,685\nColumns: 8\n$ harvest_date         <date> 1997-09-30, 1997-09-30, 1997-09-30, 1997-09-30, …\n$ harvest_moisture_pct <dbl> 8.4, 9.9, 11.0, 10.0, 10.3, 9.7, 9.7, 8.1, 9.5, 9…\n$ height_in            <dbl> 57, 62, 56, 60, 58, 58, 66, 60, 60, 54, 54, 62, 5…\n$ yield_lb_acre        <dbl> 2542, 2179, 2510, 2225, 2208, 2326, 2319, 2224, 2…\n$ year                 <int> 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1…\n$ hybrid               <chr> \"AP2098\", \"AP3470\", \"AK7304\", \"AK7305\", \"AK7306\",…\n$ emergence_date       <date> NA, 1997-05-31, 1997-05-31, NA, NA, NA, NA, 1997…\n$ planting_date        <date> 1997-05-29, 1997-05-29, 1997-05-29, 1997-05-29, …\n\nwrite.csv(df, \"example_data/sunflower_data_1.csv\", row.names = FALSE)"
  },
  {
    "objectID": "duplicate_data.html",
    "href": "duplicate_data.html",
    "title": "3. Duplicated sata",
    "section": "",
    "text": "Load packages\n\nlibrary(tidyverse) # general data wrangling\nlibrary(summarytools) # counts complete duplicates\nlibrary(janitor) # finds user defined duplicates\n\nIf you have already completed the Scrambled data types module you will have created this file. For those who prefer to jump in at the middle, the original dataset with mis-entered dates and missing value codes FIXED can be downloaded here and tucked into your example_data directory.\n\ndf <- read.csv(\"example_data/sunflower_data_1.csv\")\n\nThe summarytools package introduced in the Missing data module includes information on the number of complete duplicates (all values identical) in our dataset. We can also get this information from one line of code.\n\nsum(duplicated(df))\n\n[1] 0\n\n\nBut what if we understood that each hybrid was only planted once per year? We might then want the count of instances where combinations of year and hybrid are duplicated.\n\nsum(duplicated(df %>%\n  select(year, hybrid)))\n\n[1] 4\n\n\nNote that the duplicated functions considers anything after the first instance to be a duplicate, some of these may be triplicates or quadriplicates!! So a count of 4 here might mean one combination that exists 5 times, or 4 pairs, or one triplicate and one duplicate.\nFor more advanced duplicate sleuthing, check out the janitor package. The get_dupes function returns the rows that are duplicated and inserts a count of the duplicates. This suite of functions can be very helpful in sussing out why duplicates are occurring and what to do with them.\n\nthese_dupes <- get_dupes(df, year, hybrid)\n\n\nView(these_dupes)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nyear\nhybrid\ndupe_count\nharvest_date\nharvest_moisture_pct\nheight_in\nyield_lb_acre\nemergence_date\nplanting_date\n\n\n\n\n1990\n8803\n2\nNA\n15.70\nNA\n2012.00\nNA\nNA\n\n\n1990\n8803\n2\nNA\n17.40\nNA\n1865.00\nNA\nNA\n\n\n2000\nHySun 530\n2\n2000-10-17\n15.60\n59.00\n1921.00\n2000-06-06\n2000-06-02\n\n\n2000\nHySun 530\n2\n2000-10-17\n13.30\n60.00\n2112.00\n2000-06-07\n2000-06-02\n\n\n2015\nFalcon\n2\n2015-11-03\n10.24\n56.69\n2008.90\n2015-06-06\n2015-06-03\n\n\n2015\nFalcon\n2\n2015-11-03\n10.12\n55.12\n2125.95\n2015-06-07\n2015-06-03\n\n\n2016\nFalcon\n2\n2016-11-09\n6.89\n60.04\n1522.60\nNA\n2016-05-27\n\n\n2016\nFalcon\n2\n2016-11-09\n7.71\n58.07\n1683.70\nNA\n2016-05-27\n\n\n\n\n\nGetting rid of exact duplicates (for example if you find you entered the same data twice) is very easy using the distinct function. In this case, this won’t accomplish anything because our data are not exact duplicates.\n\ndf <- df %>%\n  distinct()\n\nRecords that are partial duplicates (such as the example above) often require going back to the original paper datasheets to check which record is correct. Perhaps one of the rows above was actually a different year, for example. In other cases, re-reading the protocol to understand the replication structure may illuminate why these ‘apparent’ duplicates exist and the statistical analysis can be adjusted accordingly."
  },
  {
    "objectID": "geocoordinates.html",
    "href": "geocoordinates.html",
    "title": "6. Geocoordinates",
    "section": "",
    "text": "df <- read.csv(\"example_data/geocoordinates_example.csv\")\n\nMany of the tricks in we learned in Data in range also apply here, but sometimes there is no substitute for a map. We can make a basic map using ggplot.\n\n# create data for world coordinates using map_data() function\nworld_coordinates <- map_data(\"world\")\n# create world map using ggplot() function\nggplot() +\n  # to make it not complain about x,y undefined\n  geom_blank(data = world_coordinates, aes(x = long, y = lat)) +\n  geom_map(\n    data = world_coordinates,\n    map = world_coordinates,\n    aes(\n      map_id = region\n    ),\n    color = \"white\", fill = \"blue\", linewidth = 0.2\n  ) +\n  geom_point(\n    data = df,\n    aes(long, lat),\n    alpha = 1, color = \"orange\"\n  ) +\n  # legend.position as none removes the legend\n  theme(legend.position = \"none\")\n\n\n\n\nOr make an interactive map using leaflet - this allows you to pan around imagery and see where on the ground those points really are.\n\n# helpful examples here https://waterdata.usgs.gov/blog/basemaps/\n\n# attribution text to display in the map using HTML\natt <- paste0(\n  \"<a href='https://www.usgs.gov/'>\",\n  \"U.S. Geological Survey</a> | \",\n  \"<a href='https://www.usgs.gov/laws/policies_notices.html'>\",\n  \"Policies</a>\"\n)\n\nGetURL <- function(service, host = \"basemap.nationalmap.gov\") {\n  sprintf(\"https://%s/arcgis/services/%s/MapServer/WmsServer\", host, service)\n}\n\n\nleaflet::leaflet() %>%\n  leaflet::addWMSTiles(., GetURL(\"USGSImageryTopo\"),\n    group = \"USGS Imagery Topo\", attribution = att, layers = \"0\"\n  ) %>%\n  leaflet::addCircles(.,\n    data = df,\n    lng = ~long, lat = ~lat,\n    color = ~\"orange\",\n    radius = 20000,\n    stroke = TRUE,\n    opacity = 5,\n    weight = 1,\n    fillOpacity = 1\n  )\n\n\n\n\n\n\n\n\n\nYou may ask yourself - did I sample in Asia? If not, quite likely some of your longitudes are lacking the sign convention to tell you that they are sampled in the western hemisphere. If you have done this, you are not alone! For example, can you see the “mirror image” of the US species occurrence records here in the raw data submitted to GBIF?\n\nImages courtesy of the developers at GBIF, who have corrected this problem. You can read more about it here."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "8ish simple rules for quality controlling your data",
    "section": "",
    "text": "This is a work in progress!\nIf you find errors in the tutorial, please make a git issue here\nI find online tutorials ‘stick’ better when you work through them with a friend, so I encourage everyone to grab a partner and dig in. Sample datasets are included, but the idea is to use these tools to qc your own data, so feel free to swap in a dataset of your choosing."
  },
  {
    "objectID": "logic_tests.html",
    "href": "logic_tests.html",
    "title": "8. Logic tests",
    "section": "",
    "text": "library(tidyverse) # general data wrangling\n\nKnowing particular things about your data will help you check for internal consistency and spot additional errors. For example, plants (usually) get larger over time, and it’s difficult to die before you are born.\n\n#here we'll use the readr function read_csv to read our data\n# readr \"knows\" about dates, which can save us some typing\ndf <- read_csv(\"example_data/sunflower_data_1.csv\")\n\nRows: 2685 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): hybrid\ndbl  (4): harvest_moisture_pct, height_in, yield_lb_acre, year\ndate (3): harvest_date, emergence_date, planting_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nIn our particular example, we will check whether emergence follows planting and harvest follows emergence.\n\nView(df %>%\n  filter(emergence_date <= planting_date | emergence_date >= harvest_date | harvest_date <= planting_date) %>%\n  select(planting_date, emergence_date, harvest_date))\n\nWhat is wrong with these data?\n\n\n\n\n\nplanting_date\nemergence_date\nharvest_date\n\n\n\n\n1999-06-03\n1999-06-03\n1999-10-13\n\n\n1999-06-05\n1999-06-03\n1999-10-13\n\n\n1999-06-06\n1999-06-03\n1999-10-13\n\n\n1999-06-07\n1999-06-03\n1999-10-13\n\n\n1999-06-08\n1999-06-03\n1999-10-13\n\n\n1999-06-09\n1999-06-04\n1999-10-13\n\n\n1999-06-10\n1999-06-04\n1999-10-13\n\n\n1999-06-11\n1999-06-08\n1999-10-13\n\n\n1999-06-12\n1999-06-05\n1999-10-13\n\n\n1999-06-13\n1999-06-05\n1999-10-13\n\n\n1999-06-14\n1999-06-03\n1999-10-13\n\n\n1999-06-15\n1999-06-06\n1999-10-13\n\n\n1999-06-16\n1999-06-07\n1999-10-13\n\n\n1999-06-17\n1999-06-05\n1999-10-13\n\n\n1999-06-18\n1999-06-03\n1999-10-13\n\n\n1999-06-19\n1999-06-04\n1999-10-13\n\n\n1999-06-20\n1999-06-06\n1999-10-13\n\n\n1999-06-21\n1999-06-03\n1999-10-13\n\n\n1999-06-22\n1999-06-02\n1999-10-13\n\n\n1999-06-23\n1999-06-04\n1999-10-13\n\n\n1999-06-24\n1999-06-04\n1999-10-13\n\n\n1999-06-25\n1999-06-04\n1999-10-13\n\n\n1999-06-26\n1999-06-05\n1999-10-13\n\n\n1999-06-27\n1999-06-06\n1999-10-13\n\n\n1999-06-28\n1999-06-06\n1999-10-13\n\n\n1999-06-29\n1999-06-04\n1999-10-13\n\n\n1999-06-30\n1999-06-06\n1999-10-13\n\n\n1999-07-01\n1999-06-02\n1999-10-13\n\n\n1999-07-02\n1999-06-03\n1999-10-13\n\n\n1999-07-03\n1999-06-05\n1999-10-13\n\n\n1999-07-04\n1999-06-03\n1999-10-13\n\n\n1999-07-05\n1999-06-05\n1999-10-13\n\n\n1999-07-06\n1999-06-04\n1999-10-13\n\n\n1999-07-07\n1999-06-08\n1999-10-13\n\n\n1999-07-08\n1999-06-03\n1999-10-13\n\n\n1999-07-09\n1999-06-05\n1999-10-13\n\n\n1999-07-10\n1999-06-02\n1999-10-13\n\n\n1999-07-11\n1999-06-04\n1999-10-13\n\n\n1999-07-12\n1999-06-03\n1999-10-13\n\n\n1999-07-13\n1999-06-02\n1999-10-13\n\n\n\n\n\nThe error reflects an amazingly common issue when keying data into excel or other spreadsheets - the ‘drag down’ feature often autofills sequential numbers or dates, rather than a constant. Microsoft Excel is trying to read your mind and doing a terrible job of it. Use caution!\nWhat other logic checks might we write to detect this kind of error?"
  },
  {
    "objectID": "missing.html",
    "href": "missing.html",
    "title": "Do I have strings intermixed with numbers and dates?",
    "section": "",
    "text": "Load packages\n\nlibrary (datacleanr) # for interactive data viz\nlibrary(naniar) # to homogenize missing value codes\nlibrary (tidyverse) #general data wrangling\nlibrary (dplyr) #general data wrangling\n\n\ndf <-read.csv ('example_data/sunflower_data_broken.csv')\n\nTo understand a little bit about the data, it can be helpful to get a brief summary of the contents\n\ndplyr::glimpse(df)\n\nRows: 2,756\nColumns: 8\n$ X                    <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15…\n$ harvest_date         <int> 19970930, 19970930, 19970930, 19970930, 19970930,…\n$ harvest_moisture_pct <dbl> 8.4, 9.9, 11.0, 10.0, 10.3, 9.7, 9.7, 8.1, 9.5, 9…\n$ height_in            <chr> \"57\", \"62\", \"56\", \"60\", \"58\", \"58\", \"66\", \"60\", \"…\n$ planting_date        <chr> \"19970529\", \"19970529\", \"19970529\", \"19970529\", \"…\n$ yield_lb_acre        <dbl> 2542, 2179, 2510, 2225, 2208, 2326, 2319, 2224, 2…\n$ Year                 <int> 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1…\n$ Hybrid               <chr> \"AP2098\", \"AP3470\", \"AK7304\", \"AK7305\", \"AK7306\",…\n\n\nA glimpse at our dataset tells us something about its structure. Ideally, you are the data collector and already know all of this. The first column (X) appears to be an index variable. Sometimes this is intentional; more often it occurs when people write out files in R and forget to include the row.names = F argument. Some things should strike you as potentially problematic about this dataset:\n\nThere are two date fields, but one is encoded as a character and one as an integer.\nHeight (with units inches) is encoded as a character.\n\nIt is very easy to convert everything that should be numeric into a numeric field, but at the risk of wiping out actual data. Better is to suss out what those mystery values are, and why they are there in the first place.\n\nsource('functions/functions.R')\n#define numeric columns\nnon_numeric_cols <-'Hybrid'\nnumeric_cols <- setdiff(names(df), non_numeric_cols)\n\n#set up a list to put numeric check results into\nall_checks <- list()\n\nfor (i in numeric_cols) {\n  all_checks[[i]] <- check_non_numeric(df, i)\n}\n\nall values are numeric for  X \nall values are numeric for  harvest_date \nall values are numeric for  harvest_moisture_pct \n\n\nWarning in check_non_numeric(df, i): Check file for height_in \n\n\nWarning in check_non_numeric(df, i): Check file for planting_date \n\n\nall values are numeric for  yield_lb_acre \nall values are numeric for  Year \n\n# resulting list will just have the things you still need to check\nnames(all_checks)\n\n[1] \"height_in\"     \"planting_date\"\n\n\n\nView(all_checks[[\"height_in\"]])\n\n\n\n\n\n \n  \n      \n    X \n    harvest_date \n    harvest_moisture_pct \n    height_in \n    planting_date \n    yield_lb_acre \n    Year \n    Hybrid \n  \n \n\n  \n    40 \n    40 \n    19970930 \n    9.5 \n    na \n    19970529 \n    2381 \n    1997 \n    ST2117 \n  \n  \n    475 \n    475 \n    20021031 \n    13.3 \n    N/A \n    20020529 \n    2008 \n    2002 \n    F00001 \n  \n\n\n\n\n\nWe can see from the above there are two different missing value codes included in the height column. Having confidence in the issues, we can now set those to a proper missing value code. Here I’m going to run on the assumption that these two missing value codes may be found elsewhere, and replace them everywhere\n\n#replace non-standard missing value codes\ndf <- df %>% replace_with_na_all(\n  condition =\n    ~ .x %in% c(\"N/A\", \"na\")\n)\n\n\n# resulting list will just have the things you still need to check\nnames(all_checks)\n\n[1] \"height_in\"     \"planting_date\"\n\n\n\nView(all_checks[[\"planting_date\"]])\n\n\n\n\n\n \n  \n      \n    X \n    harvest_date \n    harvest_moisture_pct \n    height_in \n    planting_date \n    yield_lb_acre \n    Year \n    Hybrid \n  \n \n\n  \n    938 \n    938 \n    20101021 \n    11.7 \n    63 \n    5/20/2010 \n    1032 \n    2010 \n    F30008NS,CL \n  \n  \n    939 \n    939 \n    20101021 \n    8.2 \n    64 \n    5/20/2010 \n    1244 \n    2010 \n    F51122NS,CL \n  \n  \n    940 \n    940 \n    20101021 \n    8.6 \n    66 \n    5/20/2010 \n    1290 \n    2010 \n    F51137NS,CL \n  \n  \n    941 \n    941 \n    20101021 \n    9.4 \n    71 \n    5/20/2010 \n    1354 \n    2010 \n    F51139NS,DM,CL \n  \n  \n    942 \n    942 \n    20101021 \n    11.0 \n    67 \n    5/20/2010 \n    1236 \n    2010 \n    F51313NS,DM,CL \n  \n  \n    943 \n    943 \n    20101021 \n    9.3 \n    64 \n    5/20/2010 \n    664 \n    2010 \n    F89036NS,DM,CL \n  \n  \n    944 \n    944 \n    20101021 \n    10.0 \n    69 \n    5/20/2010 \n    230 \n    2010 \n    F89057NS,SU \n  \n  \n    945 \n    945 \n    20101021 \n    8.4 \n    58 \n    5/20/2010 \n    1153 \n    2010 \n    F91033NS,SU \n  \n  \n    946 \n    946 \n    20101021 \n    9.9 \n    65 \n    5/20/2010 \n    759 \n    2010 \n    306 DMR NS \n  \n  \n    947 \n    947 \n    20101021 \n    8.5 \n    62 \n    5/20/2010 \n    1592 \n    2010 \n    3080 DMR NS \n  \n  \n    948 \n    948 \n    20101021 \n    8.7 \n    66 \n    5/20/2010 \n    1860 \n    2010 \n    356A NS \n  \n  \n    949 \n    949 \n    20101021 \n    10.5 \n    70 \n    5/20/2010 \n    1221 \n    2010 \n    378 DMR HO \n  \n  \n    950 \n    950 \n    20101021 \n    9.5 \n    70 \n    5/20/2010 \n    796 \n    2010 \n    460 E, NS \n  \n  \n    951 \n    951 \n    20101021 \n    9.9 \n    70 \n    5/20/2010 \n    1444 \n    2010 \n    555 CL DMR NS \n  \n  \n    952 \n    952 \n    20101021 \n    12.8 \n    65 \n    5/20/2010 \n    951 \n    2010 \n    559 CL DMR NS \n  \n  \n    953 \n    953 \n    20101021 \n    9.0 \n    63 \n    5/20/2010 \n    945 \n    2010 \n    564 CL NS \n  \n  \n    954 \n    954 \n    20101021 \n    12.3 \n    75 \n    5/20/2010 \n    1043 \n    2010 \n    6007 \n  \n  \n    955 \n    955 \n    20101021 \n    8.8 \n    71 \n    5/20/2010 \n    288 \n    2010 \n    7052 \n  \n  \n    956 \n    956 \n    20101021 \n    9.2 \n    67 \n    5/20/2010 \n    1172 \n    2010 \n    7163 \n  \n  \n    957 \n    957 \n    20101021 \n    8.5 \n    69 \n    5/20/2010 \n    785 \n    2010 \n    8037 \n  \n  \n    958 \n    958 \n    20101021 \n    8.7 \n    67 \n    5/20/2010 \n    439 \n    2010 \n    8064 \n  \n  \n    959 \n    959 \n    20101021 \n    9.1 \n    60 \n    5/20/2010 \n    1222 \n    2010 \n    724 NSCL \n  \n  \n    960 \n    960 \n    20101021 \n    8.9 \n    57 \n    5/20/2010 \n    849 \n    2010 \n    735 NSCLDM \n  \n  \n    961 \n    961 \n    20101021 \n    8.1 \n    70 \n    5/20/2010 \n    1340 \n    2010 \n    IX10-10576 \n  \n  \n    962 \n    962 \n    20101021 \n    10.1 \n    67 \n    5/20/2010 \n    1217 \n    2010 \n    IX10-94 NSSU \n  \n  \n    963 \n    963 \n    20101021 \n    10.6 \n    65 \n    5/20/2010 \n    330 \n    2010 \n    IX10-96 NSSU \n  \n  \n    964 \n    964 \n    20101021 \n    11.4 \n    70 \n    5/20/2010 \n    1140 \n    2010 \n    IX10-98 NSSU \n  \n  \n    965 \n    965 \n    20101021 \n    13.9 \n    62 \n    5/20/2010 \n    736 \n    2010 \n    8D310 \n  \n  \n    966 \n    966 \n    20101021 \n    10.6 \n    58 \n    5/20/2010 \n    991 \n    2010 \n    8D481 \n  \n  \n    967 \n    967 \n    20101021 \n    8.4 \n    63 \n    5/20/2010 \n    1397 \n    2010 \n    8H288CLDM \n  \n  \n    968 \n    968 \n    20101021 \n    8.9 \n    57 \n    5/20/2010 \n    1176 \n    2010 \n    8H449DM \n  \n  \n    969 \n    969 \n    20101021 \n    8.7 \n    64 \n    5/20/2010 \n    1188 \n    2010 \n    8N270CLDM \n  \n  \n    970 \n    970 \n    20101021 \n    9.0 \n    61 \n    5/20/2010 \n    1258 \n    2010 \n    8N358CLDM \n  \n  \n    971 \n    971 \n    20101021 \n    9.2 \n    61 \n    5/20/2010 \n    1236 \n    2010 \n    8N433DM \n  \n  \n    972 \n    972 \n    20101021 \n    13.5 \n    68 \n    5/20/2010 \n    1077 \n    2010 \n    LN9692 \n  \n  \n    973 \n    973 \n    20101021 \n    12.9 \n    72 \n    5/20/2010 \n    799 \n    2010 \n    LN9714 \n  \n  \n    974 \n    974 \n    20101021 \n    9.1 \n    66 \n    5/20/2010 \n    1353 \n    2010 \n    LN9987 \n  \n  \n    975 \n    975 \n    20101021 \n    12.6 \n    67 \n    5/20/2010 \n    816 \n    2010 \n    MN12138 \n  \n  \n    976 \n    976 \n    20101021 \n    11.6 \n    70 \n    5/20/2010 \n    1287 \n    2010 \n    PAN 7813NS \n  \n  \n    977 \n    977 \n    20101021 \n    12.5 \n    67 \n    5/20/2010 \n    1199 \n    2010 \n    PAN 7924NS \n  \n  \n    978 \n    978 \n    20101021 \n    10.8 \n    69 \n    5/20/2010 \n    1173 \n    2010 \n    PAN 8466 NSCL \n  \n  \n    979 \n    979 \n    20101021 \n    10.5 \n    63 \n    5/20/2010 \n    1445 \n    2010 \n    PEX 7404 \n  \n  \n    980 \n    980 \n    20101021 \n    9.2 \n    60 \n    5/20/2010 \n    1146 \n    2010 \n    PEX 7803 \n  \n  \n    981 \n    981 \n    20101021 \n    12.5 \n    64 \n    5/20/2010 \n    1523 \n    2010 \n    PEX 7904 \n  \n  \n    982 \n    982 \n    20101021 \n    10.5 \n    65 \n    5/20/2010 \n    673 \n    2010 \n    63N82 \n  \n  \n    983 \n    983 \n    20101021 \n    10.7 \n    61 \n    5/20/2010 \n    976 \n    2010 \n    P63ME70 \n  \n  \n    984 \n    984 \n    20101021 \n    11.3 \n    65 \n    5/20/2010 \n    520 \n    2010 \n    P64HE01 \n  \n  \n    985 \n    985 \n    20101021 \n    13.9 \n    66 \n    5/20/2010 \n    1137 \n    2010 \n    CL 7001 \n  \n  \n    986 \n    986 \n    20101021 \n    12.4 \n    62 \n    5/20/2010 \n    1149 \n    2010 \n    CL 9001 \n  \n  \n    987 \n    987 \n    20101021 \n    10.8 \n    66 \n    5/20/2010 \n    906 \n    2010 \n    E-4 \n  \n  \n    988 \n    988 \n    20101021 \n    10.8 \n    71 \n    5/20/2010 \n    814 \n    2010 \n    E-5 \n  \n  \n    989 \n    989 \n    20101021 \n    12.7 \n    72 \n    5/20/2010 \n    507 \n    2010 \n    E-8 \n  \n  \n    990 \n    990 \n    20101021 \n    12.8 \n    69 \n    5/20/2010 \n    913 \n    2010 \n    E-85 \n  \n  \n    991 \n    991 \n    20101021 \n    8.2 \n    58 \n    5/20/2010 \n    1212 \n    2010 \n    Badger CL \n  \n  \n    992 \n    992 \n    20101021 \n    8.8 \n    62 \n    5/20/2010 \n    1097 \n    2010 \n    Blazer CL \n  \n  \n    993 \n    993 \n    20101021 \n    8.6 \n    65 \n    5/20/2010 \n    908 \n    2010 \n    Cobra \n  \n  \n    994 \n    994 \n    20101021 \n    8.6 \n    63 \n    5/20/2010 \n    1177 \n    2010 \n    Firebird \n  \n  \n    995 \n    995 \n    20101021 \n    8.8 \n    59 \n    5/20/2010 \n    745 \n    2010 \n    X9464 \n  \n  \n    996 \n    996 \n    20101021 \n    8.3 \n    56 \n    5/20/2010 \n    840 \n    2010 \n    X9828 \n  \n  \n    997 \n    997 \n    20101021 \n    12.5 \n    70 \n    5/20/2010 \n    1422 \n    2010 \n    X9866 \n  \n  \n    998 \n    998 \n    20101021 \n    8.9 \n    61 \n    5/20/2010 \n    906 \n    2010 \n    3433 NS/DM \n  \n  \n    999 \n    999 \n    20101021 \n    9.1 \n    58 \n    5/20/2010 \n    982 \n    2010 \n    3480 NS/CL/DM \n  \n  \n    1000 \n    1000 \n    20101021 \n    10.2 \n    63 \n    5/20/2010 \n    1794 \n    2010 \n    3732 NS \n  \n  \n    1001 \n    1001 \n    20101021 \n    8.5 \n    58 \n    5/20/2010 \n    1623 \n    2010 \n    3845 HO \n  \n  \n    1002 \n    1002 \n    20101021 \n    8.4 \n    68 \n    5/20/2010 \n    1854 \n    2010 \n    3875 NS \n  \n  \n    1003 \n    1003 \n    20101021 \n    10.6 \n    66 \n    5/20/2010 \n    1031 \n    2010 \n    3980 NS/CL \n  \n  \n    1004 \n    1004 \n    20101021 \n    10.5 \n    62 \n    5/20/2010 \n    877 \n    2010 \n    4596 HO/DM \n  \n  \n    1005 \n    1005 \n    20101021 \n    9.3 \n    59 \n    5/20/2010 \n    1042 \n    2010 \n    4651 NS/DM \n  \n  \n    1006 \n    1006 \n    20101021 \n    8.4 \n    59 \n    5/20/2010 \n    662 \n    2010 \n    7120 HO/DM \n  \n  \n    1007 \n    1007 \n    20101021 \n    9.3 \n    60 \n    5/20/2010 \n    1030 \n    2010 \n    610CLD \n  \n  \n    1008 \n    1008 \n    20101021 \n    11.5 \n    64 \n    5/20/2010 \n    1117 \n    2010 \n    810HCLD \n  \n  \n    1009 \n    1009 \n    20101021 \n    9.1 \n    48 \n    5/20/2010 \n    1513 \n    2010 \n    s671 \n  \n  \n    1010 \n    1010 \n    20101021 \n    10.0 \n    52 \n    5/20/2010 \n    1093 \n    2010 \n    s673 \n  \n  \n    1011 \n    1011 \n    20101021 \n    10.2 \n    72 \n    5/20/2010 \n    1284 \n    2010 \n    TRX7435HO \n  \n  \n    1012 \n    1012 \n    20101021 \n    9.7 \n    60 \n    5/20/2010 \n    1291 \n    2010 \n    TRX8341 \n  \n  \n    1013 \n    1013 \n    20101021 \n    8.4 \n    63 \n    5/20/2010 \n    861 \n    2010 \n    894 \n  \n\n\n\n\n\nIt appears that some of the data have dates encoded as an 8 digit integer YYYYMMDD while others have M/D/YYYY. With this information, we can standardize the dates two ways, and then consolidate into a single, proper date column\n\ndf <- df %>%\n  rename(planting_date_original = planting_date) %>%\n  mutate(yyyymmdd= lubridate::ymd(planting_date_original),\n         mdy = lubridate::mdy(planting_date_original),\n         planting_date_corrected = coalesce(yyyymmdd, mdy))\n\nWarning: There were 2 warnings in `mutate()`.\nThe first warning was:\nℹ In argument: `yyyymmdd = lubridate::ymd(planting_date_original)`.\nCaused by warning:\n!  145 failed to parse.\nℹ Run `dplyr::last_dplyr_warnings()` to see the 1 remaining warning.\n\n#always check your work\nsanity_test <- df %>% \n  filter(Year %in% c(2008:2012)) %>%\n  select(planting_date_original, planting_date_corrected) %>%\n  distinct()\n\nAlways check your work!!\n\n\n\n\n \n  \n    planting_date_original \n    planting_date_corrected \n  \n \n\n  \n    20090527 \n    2009-05-27 \n  \n  \n    5/20/2010 \n    2010-05-20 \n  \n  \n    20120606 \n    2012-06-06 \n  \n  \n    NA \n    NA \n  \n\n\n\n\n\nFinally, we can remove the temporary columns we created, and set all our remaining columns to the correct column types\n\n\nRows: 2,756\nColumns: 8\n$ x                    <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15…\n$ harvest_date         <date> 1997-09-30, 1997-09-30, 1997-09-30, 1997-09-30, …\n$ harvest_moisture_pct <dbl> 8.4, 9.9, 11.0, 10.0, 10.3, 9.7, 9.7, 8.1, 9.5, 9…\n$ height_in            <dbl> 57, 62, 56, 60, 58, 58, 66, 60, 60, 54, 54, 62, 5…\n$ yield_lb_acre        <dbl> 2542, 2179, 2510, 2225, 2208, 2326, 2319, 2224, 2…\n$ year                 <int> 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1…\n$ hybrid               <chr> \"AP2098\", \"AP3470\", \"AK7304\", \"AK7305\", \"AK7306\",…\n$ planting_date        <date> 1997-05-29, 1997-05-29, 1997-05-29, 1997-05-29, …\n\n\nTo explore our data, we will first use the datacleanr package. This is an interactive tool that launches a shiny website for exploring your data. More in depth tutorials can be found using the author’s link above.\nThe dcr_app() command launches the interactive app.\n\n#dcr_app(df)\n\n\n# nas can read in multiple ways with vs without quotes\n# sarah add some examples of these here\ndf <- df %>% replace_with_na_all(\n  condition =\n    ~ .x %in% c(\"NA\", \"na\", \"--\", \"-\", '\\\\')\n)\n\nLaunch datacleanr’s interactive app with dcr_app(). The following examples demonstrate basic use and highlight features across the four app tabs."
  },
  {
    "objectID": "missing_data.html",
    "href": "missing_data.html",
    "title": "2. Missing data",
    "section": "",
    "text": "Load packages\n\nlibrary (tidyverse) #general data wrangling\nlibrary (summarytools)\n\nIf you have already completed the Scrambled data types module you will have created this file. For those who prefer to jump in at the middle, the original dataset with mis-entered dates and missing value codes FIXED can be downloaded provided here and tucked into your example_data directory.\n\ndf <-read.csv ('example_data/sunflower_data_1.csv')\n\nWe will be using the summarytools package can give us a nice overview of our dataset, including the percent of missing values (NAs) recorded in each variable.\n\nview(dfSummary(df))\n\n\n\n\n\nData Frame Summary\ndf\nDimensions: 2685 x 8\n  Duplicates: 0\n\n\n  \n    \n      Variable\n      Stats / Values\n      Freqs (% of Valid)\n      Graph\n      Missing\n    \n  \n  \n    \n      harvest_date\n[character]\n      1. 1999-10-132. 2006-10-233. 2005-10-254. 1997-09-305. 1993-10-216. 1994-10-127. 2000-10-178. 2004-10-279. 2010-10-2110. 2009-11-16[ 14 others ]\n      113(6.9%)107(6.6%)105(6.4%)99(6.1%)98(6.0%)98(6.0%)90(5.5%)80(4.9%)76(4.7%)73(4.5%)692(42.4%)\n      \n      1054\n(39.3%)\n    \n    \n      harvest_moisture_pct\n[numeric]\n      Mean (sd) : 14.3 (6.1)min ≤ med ≤ max:5.8 ≤ 11.8 ≤ 43.4IQR (CV) : 7.9 (0.4)\n      413 distinct values\n      \n      656\n(24.4%)\n    \n    \n      height_in\n[numeric]\n      Mean (sd) : 62.2 (19.6)min ≤ med ≤ max:31 ≤ 60 ≤ 188IQR (CV) : 10 (0.3)\n      376 distinct values\n      \n      398\n(14.8%)\n    \n    \n      yield_lb_acre\n[numeric]\n      Mean (sd) : 1954.6 (497.5)min ≤ med ≤ max:230 ≤ 2001 ≤ 3426IQR (CV) : 641.1 (0.3)\n      1635 distinct values\n      \n      73\n(2.7%)\n    \n    \n      year\n[integer]\n      Mean (sd) : 1999.5 (11.4)min ≤ med ≤ max:1978 ≤ 1999 ≤ 2022IQR (CV) : 17 (0)\n      40 distinct values\n      \n      0\n(0.0%)\n    \n    \n      hybrid\n[character]\n      1. 8942. Falcon3. SF1874. 1415. Badger DMR6. 8D3107. Hornet8. SF2709. 3845 HO10. 432 E[ 1757 others ]\n      27(1.0%)12(0.4%)10(0.4%)9(0.3%)9(0.3%)8(0.3%)8(0.3%)8(0.3%)7(0.3%)7(0.3%)2580(96.1%)\n      \n      0\n(0.0%)\n    \n    \n      emergence_date\n[character]\n      1. 1999-06-042. 2006-06-043. 1993-05-294. 2005-05-255. 1997-05-316. 1999-06-037. 2006-06-038. 1994-05-279. 2000-06-0410. 1993-05-28[ 144 others ]\n      34(2.5%)33(2.4%)28(2.1%)27(2.0%)25(1.8%)23(1.7%)23(1.7%)22(1.6%)22(1.6%)21(1.6%)1094(80.9%)\n      \n      1333\n(49.6%)\n    \n    \n      planting_date\n[character]\n      1. 2006-06-012. 2005-05-233. 1997-05-294. 1993-05-265. 1994-05-256. 2000-06-027. 2004-05-268. 2010-05-209. 2009-05-2710. 1991-05-28[ 56 others ]\n      107(6.9%)105(6.7%)99(6.3%)98(6.3%)98(6.3%)90(5.8%)80(5.1%)76(4.9%)73(4.7%)72(4.6%)663(42.5%)\n      \n      1124\n(41.9%)\n    \n  \n\nGenerated by summarytools 1.0.1 (R version 4.2.2)2024-02-23\n\n\n\nKnowing more about the intended sampling design will tell us what other missing values should we look for. For example, were data collected every year? If so examining the years included in the dataset may be important.\nSometimes a visual check is easy to spot what is missing\n\nsort (unique (df$year))\n\n [1] 1978 1979 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993\n[16] 1994 1996 1997 1998 1999 2000 2001 2002 2004 2005 2006 2007 2008 2009 2010\n[31] 2012 2013 2014 2015 2016 2017 2018 2020 2021 2022\n\n\nSometimes it’s hard to find exactly what is missing! setdiff (for simple checks for expected values based on complete sets) expand.grid (for checking pre-defined combinations) and the padr package (for padding out dataset based on regular temporal frequency) are your friends here. For this dataset, we’ll use the simple code below to figure out what years are missing. It is then up to you whether it is important to add those years with NA values, or just carry on knowing they are missing.\n\nsetdiff(seq(min(df$year), max(df$year)), unique(df$year))\n\n[1] 1980 1995 2003 2011 2019\n\n\nCommonly, we expect a similar number of samples over some interval (e.g. per site or year)\n\nct_by_year = df %>%\n  group_by(year) %>%\n  tally()\n\nViewing just the first 10 years, the number of datapoints is highly variable among years, is this expected?\n\n\n\n\n\nyear\nn\n\n\n\n\n1978\n26\n\n\n1979\n36\n\n\n1981\n53\n\n\n1982\n64\n\n\n1983\n69\n\n\n1984\n64\n\n\n1985\n64\n\n\n1986\n57\n\n\n1987\n64\n\n\n1988\n49"
  },
  {
    "objectID": "spelling_counts.html",
    "href": "spelling_counts.html",
    "title": "5. Spelling counts",
    "section": "",
    "text": "library(tidyverse) # general data wrangling\nlibrary(summarytools) # slick dataset summaries\n\nIf you have already completed the Scrambled data types module you will have created this file. For those who prefer to jump in at the middle, the original dataset with mis-entered dates and missing value codes FIXED can be downloaded here and tucked into your example_data directory.\n\ndf <- read.csv(\"example_data/sunflower_data_1.csv\")\n\nThe summarytools package introduced in previous modules includes information on the number most commonly encountered strings in non-numeric fields. If you have 10 or fewer categories, this can be a great way to quickly see what the most common categories are and if you have spelled them correctly.\n\n\n\n\nData Frame Summary\ndf\nDimensions: 2685 x 8\n  Duplicates: 0\n\n\n  \n    \n      Variable\n      Stats / Values\n      Freqs (% of Valid)\n      Graph\n      Missing\n    \n  \n  \n    \n      harvest_date\n[character]\n      1. 1999-10-132. 2006-10-233. 2005-10-254. 1997-09-305. 1993-10-216. 1994-10-127. 2000-10-178. 2004-10-279. 2010-10-2110. 2009-11-16[ 14 others ]\n      113(6.9%)107(6.6%)105(6.4%)99(6.1%)98(6.0%)98(6.0%)90(5.5%)80(4.9%)76(4.7%)73(4.5%)692(42.4%)\n      \n      1054\n(39.3%)\n    \n    \n      harvest_moisture_pct\n[numeric]\n      Mean (sd) : 14.3 (6.1)min ≤ med ≤ max:5.8 ≤ 11.8 ≤ 43.4IQR (CV) : 7.9 (0.4)\n      413 distinct values\n      \n      656\n(24.4%)\n    \n    \n      height_in\n[numeric]\n      Mean (sd) : 62.2 (19.6)min ≤ med ≤ max:31 ≤ 60 ≤ 188IQR (CV) : 10 (0.3)\n      376 distinct values\n      \n      398\n(14.8%)\n    \n    \n      yield_lb_acre\n[numeric]\n      Mean (sd) : 1954.6 (497.5)min ≤ med ≤ max:230 ≤ 2001 ≤ 3426IQR (CV) : 641.1 (0.3)\n      1635 distinct values\n      \n      73\n(2.7%)\n    \n    \n      year\n[integer]\n      Mean (sd) : 1999.5 (11.4)min ≤ med ≤ max:1978 ≤ 1999 ≤ 2022IQR (CV) : 17 (0)\n      40 distinct values\n      \n      0\n(0.0%)\n    \n    \n      hybrid\n[character]\n      1. 8942. Falcon3. SF1874. 1415. Badger DMR6. 8D3107. Hornet8. SF2709. 3845 HO10. 432 E[ 1757 others ]\n      27(1.0%)12(0.4%)10(0.4%)9(0.3%)9(0.3%)8(0.3%)8(0.3%)8(0.3%)7(0.3%)7(0.3%)2580(96.1%)\n      \n      0\n(0.0%)\n    \n    \n      emergence_date\n[character]\n      1. 1999-06-042. 2006-06-043. 1993-05-294. 2005-05-255. 1997-05-316. 1999-06-037. 2006-06-038. 1994-05-279. 2000-06-0410. 1993-05-28[ 144 others ]\n      34(2.5%)33(2.4%)28(2.1%)27(2.0%)25(1.8%)23(1.7%)23(1.7%)22(1.6%)22(1.6%)21(1.6%)1094(80.9%)\n      \n      1333\n(49.6%)\n    \n    \n      planting_date\n[character]\n      1. 2006-06-012. 2005-05-233. 1997-05-294. 1993-05-265. 1994-05-256. 2000-06-027. 2004-05-268. 2010-05-209. 2009-05-2710. 1991-05-28[ 56 others ]\n      107(6.9%)105(6.7%)99(6.3%)98(6.3%)98(6.3%)90(5.8%)80(5.1%)76(4.9%)73(4.7%)72(4.6%)663(42.5%)\n      \n      1124\n(41.9%)\n    \n  \n\nGenerated by summarytools 1.0.1 (R version 4.2.2)2024-02-23\n\n\n\nThis problem gets more complex when there are 1767 categories!! Careful inspection can help. For instance we could view the entire table, sorted alphabetically\n\nhybrid_names <- df %>%\n  select(hybrid) %>%\n  distinct() %>%\n  arrange(hybrid)\n\nLet’s look at the top 40.\n\n\n\n\n\nhybrid\n\n\n\n\n02TH03896\n\n\n03TH004205\n\n\n03TH004251\n\n\n06EX05\n\n\n08EXP01\n\n\n10\n\n\n101\n\n\n103\n\n\n107\n\n\n109\n\n\n115\n\n\n11G04\n\n\n11G08\n\n\n11G12\n\n\n11G13\n\n\n11N94\n\n\n120\n\n\n121\n\n\n1266\n\n\n1296\n\n\n12E06\n\n\n12E12\n\n\n12E13\n\n\n12E14\n\n\n12G04\n\n\n12G20\n\n\n12G25\n\n\n12G25 CL\n\n\n12G25CL\n\n\n12G28\n\n\n12H92\n\n\n12N92\n\n\n13-652 CL\n\n\n1300\n\n\n131\n\n\n134A\n\n\n14-572 CL\n\n\n140\n\n\n141\n\n\n1424\n\n\n\n\n\nIt often takes some common sense to figure out what is spelled wrong. Sometimes differing in only one digit is meaningful, sometimes that is a typo. Commonly, errors involve things like capitalization and spacing.\nIn our particular example, it seems that sometimes a space has been entered in the middle of some varieties by one person who keyed in data, but not another, e.g. 12G25 CL vs 12G25CL. You have some options here. First, you could go back and correct those typos in the data. For a small volume of data, that’s often a great option.\nAnother option would be to correct each variety name using R code. For instance, if we knew that all instances of 12G25 CL should actually have been entered as 12G25CL and 20-EXP05 is really 20-EXP5, we could fix those errors using a few lines of code\n\ndf <- df %>%\n  # create a new variable\n  mutate(\n    hybrid_fixed =\n      case_when(\n        hybrid == \"12G25 CL\" ~ \"12G25CL\",\n        hybrid == \"20-EXP05\" ~ \"20-EXP5\",\n        TRUE ~ hybrid\n      )\n  )\n\nCheck your work!\n\nView(df %>%\n  select(hybrid, hybrid_fixed) %>%\n  distinct() %>%\n  # this allows us to easily view which ones changed to see if we did it right\n  mutate(fixed = (hybrid != hybrid_fixed)) %>%\n  arrange(desc(fixed)))\n\n\n\n\n\n\nhybrid\nhybrid_fixed\nfixed\n\n\n\n\n12G25 CL\n12G25CL\nTRUE\n\n\n20-EXP05\n20-EXP5\nTRUE\n\n\nAP2098\nAP2098\nFALSE\n\n\nAP3470\nAP3470\nFALSE\n\n\nAK7304\nAK7304\nFALSE\n\n\nAK7305\nAK7305\nFALSE\n\n\nAK7306\nAK7306\nFALSE\n\n\nAK7311\nAK7311\nFALSE\n\n\nAS3211\nAS3211\nFALSE\n\n\nAS471\nAS471\nFALSE\n\n\n\n\n\nHaving reassured ourselves we fixed the problematic data without simultaneously breaking any other data we can remove the extra column.\n\ndf <- df %>%\n  # out with the bad, in with the good\n  select(-hybrid) %>%\n  rename(hybrid = hybrid_fixed)\n\nWe might also postulate that spaces are causing us problems more generally, or other characters. Would it be appropriate to remove all the spaces, tabs, newlines and carriage returns in the variety names? Learning a little about regular expressions can help you here!\n\ndf_space_removal <- df %>%\n  mutate(hybrid_no_space = gsub(\"\\\\s+\", \"\", hybrid)) %>%\n  select(hybrid_no_space, hybrid) %>%\n  distinct()\n\ndup_check <- janitor::get_dupes(df_space_removal, hybrid_no_space)\n\nBefore applying this we want to check that all sets of names we have ‘combined’ make sense. You would want to check the whole list, but just a few are displayed here for brevity.\n\n\n\n\n\nhybrid_no_space\ndupe_count\nhybrid\n\n\n\n\n8H350DM\n3\n8H350 DM\n\n\n8H350DM\n3\n8H 350 DM\n\n\n8H350DM\n3\n8H350DM\n\n\n8N337DM\n3\n8N 337 DM\n\n\n8N337DM\n3\n8N337 DM\n\n\n8N337DM\n3\n8N337DM\n\n\n8N453DM\n3\n8N453 DM\n\n\n8N453DM\n3\n8N 453 DM\n\n\n8N453DM\n3\n8N453DM\n\n\nDKF33-33NS\n3\nDKF33-33NS\n\n\nDKF33-33NS\n3\nDKF 33-33NS\n\n\nDKF33-33NS\n3\nDKF 33-33 NS\n\n\nIS4704NS\n3\nIS 4704NS\n\n\nIS4704NS\n3\nIS4704NS\n\n\nIS4704NS\n3\nIS4704 NS\n\n\n3080DMR,NS\n2\n3080DMR, NS\n\n\n3080DMR,NS\n2\n3080 DMR, NS\n\n\n4415HO/CLP/DM\n2\n4415HO/CLP/DM\n\n\n4415HO/CLP/DM\n2\n4415 HO/CLP/DM\n\n\n4421CL\n2\n4421CL\n\n\n\n\n\nLast, you might curate a list that matches the misentered name to the correct name, or use someone a published list of synonyms. As one example, the taxoncleanr package can help simplify the world of pain that is aligning taxonomic names."
  },
  {
    "objectID": "time_zones.html",
    "href": "time_zones.html",
    "title": "7. Time zones",
    "section": "",
    "text": "Time zones and loggers set to the wrong time zone are a special kind of misery. Countless blogs have been written about this particular misery, which I will not repeat here. But suffice it to say it is important to understand the time-zone of your data, if time is important!\n\n\n\n\ndf <- read.csv(\"example_data/time_zones.csv\") %>%\n  mutate(date_time = lubridate::ymd_hms(date_time))\n\nOftentimes, a plot is enough to sort this out. It helps to zoom way on in on particular period to see the time of day.\n\n# Plots a scatter plot of temperature against date_time for the first 40 rows of the input dataframe.\nggplot(head(df, 40), aes(x = date_time, y = temperature)) +\n  geom_point() +\n  theme_classic()\n\n\n\n\nThe sun only shines during the day, so variables like PAR and temperature are helpful indicators here. It is unusual for the temperature to peak just before noon. In this case, the data appear to be in UTC. Sometimes this is desirable! Other times, you may want to convert the timezone to local.\n\n# Mutates the 'date_time_colorado' column of the dataframe 'df' to force the timezone to 'America/Denver'.\ndf <- df %>%\n  mutate(date_time_colorado = force_tz(date_time, \"America/Denver\"))\n\nAs always, check your work before proceeding!\n\n# Plots temperature data against date_time in two different time zones.\n# The first plot shows the temperature data in UTC time zone, while the second plot shows the temperature data in Colorado time zone.\n# The data used for the plot is the first 40 rows of the dataframe 'df'.\n# The plot includes a legend that shows the color mapping for each time zone.\nggplot(head(df, 40), aes(x = date_time, y = temperature, color = \"black\")) +\n  geom_point(show.legend = TRUE) +\n  geom_point(data = head(df, 40), aes(x = date_time_colorado, y = temperature, color = \"red\")) +\n  theme_classic() +\n  scale_color_identity(\n    name = \"Time zone\",\n    breaks = c(\"black\", \"red\"),\n    label = c(\"UTC\", \"Colorado\"),\n    guide = \"legend\"\n  )"
  },
  {
    "objectID": "setup.html",
    "href": "setup.html",
    "title": "0. Setup",
    "section": "",
    "text": "# install packages\npackReq <- c(\n  \"tidyverse\", \"lubridate\", \"naniar\", \"summarytools\", \"leaflet\", \"mapview\", \"datacleanr\"\n)\n\n# Install and load all required packages\nlapply(packReq, function(x) {\n  print(x)\n  if (require(x, character.only = TRUE) == FALSE) {\n    install.packages(x)\n    library(x, character.only = TRUE)\n  }\n})\n\nWe will be working with some example data. To follow along exactly with the paths in this tutorial, you will need to create a folder called ‘example_data’ and download the following files into that location. The example_data should be within your working directory for Rstudio (if you want to copy and paste code snippets without changing paths).\nsunflower_data_broken.csv\ngeocoordinates_example.csv\ntime_zones.csv\nLast, we will be using the summarytools package. This should work out-of-box for windows users. Mac users may need to install XQuartz if you haven’t already. Linux - I haven’t tried - thanks for being the guinea pig and please provide feedback any OS incompatibilities. As with all things R, fighting to get the right things installed is always half the battle…sorry about that! More troubleshooting of installing the summarytools package may be found here."
  }
]